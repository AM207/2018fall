---
title: Class Material
shorttitle: Material
layout: default
nav_include: 5
noline: 1
---

## Indices

- [Lectures and Labs](lectures/) (along with readings for these lectures)
- [Videos](https://matterhorn.dce.harvard.edu/engage/ui/index.html#/2019/01/15810)
- [Homework](homeworks/index.html)
- [Topics Index](topics.html)
- [Terms Glossary](terms.html)


## Sequentially

---

### Week 1

Lecture 1: **Introduction**

[Slides and Notes](lectures/lecture1.html), [Video](https://matterhorn.dce.harvard.edu/engage/player/watch.html?id=a4a460d2-b470-4f5e-99d3-ea0f28856b5f)

Lab 1: **Bayes Theorem and Python Tech**

[Material](lectures/lab1.html), [Video](https://matterhorn.dce.harvard.edu/engage/player/watch.html?id=dffad081-ad52-4715-998d-f2fe35655167)

---

### Week 2

Lecture 2: **Probability, Sampling, and the Laws**

[Slides and Notes](lectures/lecture2.html), [Video](https://matterhorn.dce.harvard.edu/engage/player/watch.html?id=5092fc6b-1ed7-45b1-a47f-1d51fed99ce6)

Lecture 3: **From Monte Carlo to Frequentism**

[Slides and Notes](lectures/lecture3.html)

Lab2: **Frequentism, Bootstrap, and MLE**

[Material](lectures/lab2.html)

---

### Week 3

Lecture 4: **MLE, Sampling, and Learning**

[Slides and Notes](lectures/lecture4.html)

Lecture 5: **Regression, AIC, Info. Theory**

[Slides and Notes](lectures/lecture5.html)

Lab 3: **Generating regression data, fitting it, training, and testing**

[Material](lectures/lab3.html)

---

### Week 4

Lecture 6: **Risk, AIC, Info. Theory**

[Slides and Notes](lectures/lecture6.html)

Lecture 7: **From Entropy to Bayes**

[Slides and Notes](lectures/lecture7.html)

Lab 4: **Bayesian Quantities in the Globe Model**

[Material](lectures/lab4.html)

---

### Week 5

Lecture 8: **Bayes and Sampling**

[Slides and Notes](lectures/lecture8.html)

Lecture 9: **Bayes and Sampling**

[Slides and Notes](lectures/lecture9.html)

Lab 5: **Logistic Regression and Sundry Bayesian**

[Material](lectures/lab5.html)

---

### Week 6

Lecture 10: **Sampling and Gradient Descent**

[Slides and Notes](lectures/lecture10.html)

Lab 6: **Sampling and PyTorch**

[Material](lectures/lab6.html)

---

### Week 7

Lecture 11: **Gradient Descent and Neural Networks**

[Slides and Notes](lectures/lecture11.html)

Lecture 12: **Non Linear Approximation to Classification**

[Slides and Notes](lectures/lecture12.html)

Lab 7: **PyTorch**

To be linked

---

### Week 8

Lecture 13: **Classification, Mixtures, and EM**

[Slides and Notes](lectures/lecture13.html)

Lecture 14: **EM and Hierarchcal models**

[Slides and Notes](lectures/lecture14.html)

Lab 8: **EM and Hierarchicals**

[Material](lectures/lab8.html)

---

### Week 9

Lecture 15: **MCMC**

[Slides and Notes](lectures/lecture15.html)

Lecture 16: **MCMC and Gibbs**

[Slides and Notes](lectures/lecture16.html)

Lab9: **Sampling and Pymc3**

[Material](lectures/lab9.html)

---

### Week10 

Lecture 17: **Gibbs, Augmentation, and HMC**

[Slides and Notes](lectures/lecture17.html)

Lecture 18: **HMC, and Formal tests**

[Slides and Notes](lectures/lecture18.html)

Lab10: **Jacobians and Tumors**

[Material](lectures/lab10.html)

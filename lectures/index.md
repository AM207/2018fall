---
title: "Lectures"
shorttitle: Lectures
layout: "default"
---

- [Lecture 1](lecture1.html): Intro and Probability
- [Lab 1](lab1.html): Bayes Theorem and Python Tech
- [Lecture 2](lecture2.html): Probability and LLN
- [Lecture 3](lecture3.html): From Monte-Carlo to frequentism
- [Lab 2](lab2.html): Frequentism, Bootstrap, and MLE
- [Lecture 4](lecture4.html): MLE, Sampling, and Learning
- [Lecture 5](lecture5.html): Regression, AIC, Info. Theory
- [Lab 3](lab3.html): Generating regression data, fitting it, training, and testing
- [Lecture 6](lecture6.html): Risk and Information
- [Lecture 7](lecture7.html): From Entropy to Bayes
- [Lab 4](lab4.html): Bayesian Quantities in the Globe Model
- [Lecture 8](lecture8.html): Bayes and Sampling
- [Lecture 9](lecture9.html): Bayes and Sampling
- [Lab 5](lab5.html): Logistic Regression and Sundry Bayesian
- [Lecture 10](lecture10.html): Sampling and Gradient Descent
- [Lab 6](lab6.html): Sampling and PyTorch
- [Lecture 11](lecture11.html): Gradient Descent and Neural Networks
- [Lecture 12](lecture12.html): Non Linear Approximation to Classification
- [Lab 7] still to come
- [Lecture 13](lecture13.html): Classification, Mixtures, and EM
- [Lecture 14](lecture14.html): EM and Hierarchcal models
- [Lab 8](lab8.html): EM and Hierarchicals
- [Lecture 15](lecture15.html): MCMC
- [Lecture 16](lecture16.html): MCMC and Gibbs
- [Lab 9](lab9.html): Sampling and pymc3
- [Lecture 17](lecture17.html): Data Augmentation, Gibbs, and HMC
- [Lecture 18](lecture18.html): HMC, and Formal tests
- [Lab 10](lab10.html): Jacobians and Tumors
- [Lecture 19](lecture19.html): NUTS, Formal tests, and Hierarchicals
- [Lecture 20](lecture20.html): Regression, GLMs, and model specification
- [Lab 11](lab11.html): Gelman Schools Hierarchical and Prosocial Chimps GLM
- [Lecture 21](lecture21.html): From Hierarchical GLMs to Gaussian Processes
